{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Прянишников Александр, ИУ7-35Б\n",
    "# Лабораторная работа №4: классификация языков\n",
    "\n",
    "# Я не успел подсчитать всё, что хотел, так как часто были проблемы с оперативной памятью, и считается всё очень долго\n",
    "# Поэтому я просто буду обновлять комментарии, прописывая итоги моей работы\n",
    "# Перед дедлайном у меня был score 0.94, итоговое 4 место в соревновании.\n",
    "# Дальнейшие мои комментарии и действия - исключительно мой интерес."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in c:\\users\\александр\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (1.0.8)\n",
      "Requirement already satisfied: six in c:\\users\\александр\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from langdetect) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "!pip install langdetect\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing  import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from langdetect import detect\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаем константы, скачиваем данные\n",
    "SEED = 42\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сначала я пробовал очистить выборку с помощью библиотеки Langdetect\n",
    "# Считалось 8 часов, но в итоге оказалось, что ошибок стало ещё больше\n",
    "# Но код я оставлю\n",
    "\n",
    "for i in range(train_df.shape[0]):\n",
    "    lang = train_df[\"language\"][i]\n",
    "    \n",
    "    # Добавил исключения, так как в гугловской библиотеке только 55 языков\n",
    "    # И если язык не определён, то кидается исключение\n",
    "    try:\n",
    "        google_lang = detect(train_df[\"sentence\"][i])\n",
    "        if (lang != google_lang):\n",
    "            train_df[\"language\"][i] = google_lang\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "# У такого подхода два минуса\n",
    "# Во-первых, он некорректно определяет язык, причём главная беда - синтетические ошибки исчезли только на 50%\n",
    "# Во-вторых, оооочень долго\n",
    "# Поэтому больше я использовать это не буду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the and of it that you to apos we this is in they so are'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Тогда я начал вручную смотреть каждый язык, и проверять, если ли в нём синтетические ошибки\n",
    "\n",
    "# Так я смотрел первые 50 записей, и смотрел, если ли систематические ошибки\n",
    "train_df[train_df[\"language\"] == \"ru\"].head(50)\n",
    "\n",
    "# Так я копировал полную строку, которую потом надо почистать\n",
    "train_df[train_df[\"language\"] == \"ta\"][\"sentence\"][164]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исправим выборку train от искусственных ошибок\n",
    "sent_1 = \"що це тому ми чи дуже які щоб дякую якщо було вона від мене ось\"\n",
    "sent_2 = \"гэта што калі мы не яны як але ён каб дзякуй больш пра на вы\"\n",
    "sent_3 = \"это что мы не как на вы они но из то он так для аплодисменты\"\n",
    "sent_4 = \"笑聲 掌聲 謝謝 所以 現在 事實上 當然 因此 謝謝大家 對吧 但是 鼓掌 謝謝各位 他說 我說\"\n",
    "sent_5 = \"笑声 掌声 谢谢 现在 所以 事实上 当然 鼓掌 但是 因此 那么 非常感谢 谢谢大家 是的 好吧\"\n",
    "sent_6 = \"що це ми не як на вони та але ви до про він оплески коли\"\n",
    "sent_7 = \"бұл мен біз бір үшін ол деп және емес бар керек бірақ олар қол осы\"\n",
    "sent_8 = \"the and of it that you to apos we this is in they so are\"\n",
    "for i in range(train_df.shape[0]):\n",
    "    if (train_df[\"sentence\"][i] == sent_1):\n",
    "        train_df[\"language\"][i] = \"uk\"\n",
    "    elif (train_df[\"sentence\"][i] == sent_2):\n",
    "        train_df[\"language\"][i] = \"uk\"\n",
    "    elif (train_df[\"sentence\"][i] == sent_3):\n",
    "        train_df[\"language\"][i] = \"ru\"\n",
    "    # Насчёт 4 и 5 не уверен, какой из китайских, поставил китайский, который используется в Китае\n",
    "    # Там очень странное разделение\n",
    "    elif (train_df[\"sentence\"][i] == sent_4):\n",
    "        train_df[\"language\"][i] = \"zh-cn\"\n",
    "    elif (train_df[\"sentence\"][i] == sent_5):\n",
    "        train_df[\"language\"][i] = \"zh-cn\"\n",
    "    elif (train_df[\"sentence\"][i] == sent_6):\n",
    "        train_df[\"language\"][i] = \"uk\"\n",
    "    elif (train_df[\"sentence\"][i] == sent_7):\n",
    "        train_df[\"language\"][i] = \"kk\"\n",
    "    elif (train_df[\"sentence\"][i] == sent_8):\n",
    "        train_df[\"language\"][i] = \"en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Затем я использовал Tf-IDF и запустил логистическую регрессию\n",
    "new_train_df = train_df[[\"sentence\", \"language\"]]\n",
    "x = new_train_df[\"sentence\"]\n",
    "y = new_train_df[\"language\"]\n",
    "\n",
    "LE = LabelEncoder()\n",
    "y = LE.fit_transform(y)\n",
    "\n",
    "# Именно под такими параметрами у меня получился наибольший score на Kaggle\n",
    "# Я пробовал менять ngram, max_df, analyzer\n",
    "# Получилось, что на символах результат существенно лучше, а max_df не особо влияет на результат\n",
    "IDF = TfidfVectorizer(analyzer = \"char\", ngram_range=(2, 3), max_df = 0.4, min_df = 10)\n",
    "x = IDF.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=SEED, shuffle = True)\n",
    "\n",
    "LR = LogisticRegression(class_weight=\"balanced\")\n",
    "LR.fit(x_train, y_train)\n",
    "predict = LR.predict(x_test)\n",
    "balanced_accuracy_score(y_test, predict)\n",
    "\n",
    "# У меня получилось 0.94 (считал в колабе), на Kaggle практически столько же"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделал submit на Kaggle\n",
    "x_t = test_df[\"sentence\"]\n",
    "x_t = IDF.transform(x_t)\n",
    "new_pred = LR.predict(x_t)\n",
    "\n",
    "test_df['language'] = LE.classes_[new_pred]\n",
    "test_df[['index',  'language']].to_csv(\"second_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построим матрицу ошибок, чтобы понять, в каких языках ошибается система\n",
    "fig, ax = plt.subplots(figsize=(100, 100))\n",
    "plot_confusion_matrix(LR, x_test, y_test, display_labels = LE.classes_, ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обнаружены следующие пары ошибок:\n",
    "# 1: Русский и украинский часто считаются болгарскими\n",
    "# 2: Программа плохо справляется с балканскими языками, считая словенский и хорватский как боснийский\n",
    "# 3: Словенский программа считает за чешский\n",
    "# 4: Нидерладнский часто воспринимается за немецкий\n",
    "# 5: Некоторые европейские языки часто выдаются за галисийский\n",
    "# 6: Хорватский - сербский\n",
    "# 7: Куча ошибок в определении того, какой из языков - какая версия китайского\n",
    "# 8: fr и fr-cn\n",
    "# 9: Тайванский часто предсказывается неверно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь обучим RF по приколу\n",
    "RF = RandomForestClassifier(n_estimators = 10, class_weight=\"balanced\")\n",
    "RF.fit(x_train, y_train)\n",
    "predict = RF.predict(x_test)\n",
    "balanced_accuracy_score(y_test, predict)\n",
    "\n",
    "# Результат получился 0.80, при этом обучение шло очень долго."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь создадим список стоп-слов\n",
    "lang = ['hungarian', 'swedish', 'kazakh', 'norwegian', 'finnish', 'arabic', 'indonesian', 'portuguese', 'turkish', 'azerbaijani',\n",
    "         'slovene', 'spanish', 'danish', 'nepali', 'romanian', 'greek', 'dutch', 'tajik', 'german', 'english', 'russian','french','italian']\n",
    "\n",
    "stop_words = []\n",
    "for lan in lang:\n",
    "    stop_words += nltk.corpus.stopwords.words(lan)\n",
    "\n",
    "# Впоследствии оказалось, что наличие словаря стоп-слов вообще никак не влияет на качество модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проделаем тоже самое с CountVectorizer\n",
    "CV = CountVectorizer(analyzer = \"char\", lowercase=True, ngram_range=(2, 3), stop_words = stop_words, min_df = 10, max_df=0.4)\n",
    "\n",
    "new_train_df = train_df[[\"sentence\", \"language\"]]\n",
    "x = new_train_df[\"sentence\"]\n",
    "y = new_train_df[\"language\"]\n",
    "\n",
    "LE = LabelEncoder()\n",
    "y = LE.fit_transform(y)\n",
    "\n",
    "x = CV.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=SEED, shuffle = True)\n",
    "\n",
    "LR = LogisticRegression(class_weight=\"balanced\")\n",
    "LR.fit(x_train, y_train)\n",
    "predict = LR.predict(x_test)\n",
    "balanced_accuracy_score(y_test, predict)\n",
    "\n",
    "# Для этих действий у меня ни разу не хватило ОЗУ, то есть TF-IDF оказался эффективнее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь применим метод ближайших соседей, который будет считать оочень долго, но для языков может оказаться успешным\n",
    "KNN = KNNNeighborsClassifier()\n",
    "KNN.fit(x_train, y_train)\n",
    "predict = KNN.predict(x_test)\n",
    "balanced_accuracy_score(y_test, predict)\n",
    "\n",
    "# В итоге у меня так и не подсчиталось даже для одного соседа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Также на англоязычных источниках много рассказывали про Наивный Байес\n",
    "# Попробуем и его\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=SEED, shuffle = True)\n",
    "\n",
    "MN = MultinomialNB()\n",
    "MN.fit(x_train, y_train)\n",
    "pred = MN.predict(x_test)\n",
    "balanced_accuracy_score(y_test, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
